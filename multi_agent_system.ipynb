{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d08ea4",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\"https://colab.research.google.com/github/christianmoiola/agentic_lecture/multi_agent_system.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c4991",
   "metadata": {},
   "source": [
    "## 1 What is an AI Agent?\n",
    "\n",
    "An **AI Agent** is a system capable of autonomously performing tasks on behalf of a user or another system.  \n",
    "It achieves this by **planning**, **reasoning**, and **interacting** with the external environment through various tools and components.\n",
    "\n",
    "Different types of AI agents exist, such as simple reflex agents or model-based agents.\n",
    "\n",
    "Today, however, the term “AI agent” is often used to refer specifically to LLM-based agents, which use a Large Language Model as the central controller that coordinates other components such as memory and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5517e",
   "metadata": {},
   "source": [
    "## 2 Core Components of an AI Agent\n",
    "\n",
    "### 1. Model\n",
    "- Acts as the **brain** of the agent.  \n",
    "- Responsible for reasoning, understanding, and generating responses.  \n",
    "- Maintains context and makes decisions based on knowledge and prior interactions.\n",
    "\n",
    "### 2. Tools\n",
    "- External functions, APIs, or plugins that allow the agent to perform specific actions.  \n",
    "- Extend the agent’s capabilities (e.g., web search, code execution, image generation, data analysis).\n",
    "\n",
    "### 3. Instructions\n",
    "- Define the rules, goals, and behavioral constraints of the agent.  \n",
    "- Guide the agent’s tone, scope of allowed actions, and ethical boundaries.\n",
    "\n",
    "### 4. Memory\n",
    "- Stores the **state of the conversation**, including past messages, tool outputs, and contextual information.  \n",
    "- Enables continuity across multiple user interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c9873",
   "metadata": {},
   "source": [
    "## 3 How a Basic AI Agent Works\n",
    "\n",
    "When a user provides an input or question, the AI Agent processes it as follows:\n",
    "\n",
    "1. The **user query** is combined with the **system instructions** and any relevant **context or memory**.\n",
    "2. The **LLM** (foundation model) interprets the request and decides which **tool** (or set of tools) to use.\n",
    "3. The model generates a **JSON output** specifying:\n",
    "   - The **tool name** to be executed.\n",
    "   - The **parameters** required for execution.\n",
    "4. The specified tool is executed, and the resulting output is returned to the user.\n",
    "\n",
    "### Limitations of the Basic Agent\n",
    "A limitation of this approach is that it operates in a **single-shot** manner — it selects and executes tools based only on the initial input.  \n",
    "This means it cannot handle **multi-step reasoning** tasks where the output of one tool is required as input for another.\n",
    "\n",
    "To overcome this limitation, a more advanced architecture was introduced: the **ReAct Framework**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f7a17",
   "metadata": {},
   "source": [
    "## 4 The ReAct Framework\n",
    "\n",
    "The **ReAct Framework** (Reason + Act) extends the capabilities of AI Agents by integrating **iterative reasoning** and **tool use** in a looped process.\n",
    "\n",
    "- **Reasoning (Reason)**:  \n",
    "  The model first reflects on the problem and determines the steps needed to solve it.  \n",
    "  This encourages **step-by-step logical planning** before any action is taken.\n",
    "\n",
    "- **Action (Act)**:  \n",
    "  Based on its reasoning, the model selects and executes the appropriate tools.  \n",
    "  The results of these actions are then fed back into the reasoning loop.\n",
    "\n",
    "This iterative process continues until the agent produces a **final answer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf988f",
   "metadata": {},
   "source": [
    "## 5 How a ReAct AI Agent Works\n",
    "\n",
    "[![HMD-2.png](https://i.postimg.cc/qMVsdKD4/HMD-2.png)](https://postimg.cc/LhDYtJMb)\n",
    "\n",
    "Below is the general workflow of a ReAct-based AI Agent:\n",
    "\n",
    "1. **Initialization**\n",
    "   - The system prompt (instructions), user query, and any prior observations (results from earlier tool executions) are concatenated into a single input prompt.\n",
    "\n",
    "2. **Reasoning and Action Generation**\n",
    "   - The LLM receives this prompt and outputs two components sequentially:\n",
    "     1. **Thought**: A reasoning step describing how the model plans to approach the problem.\n",
    "     2. **Action**: A JSON-formatted instruction specifying which tool to call and with what parameters.\n",
    "\n",
    "3. **Tool Execution**\n",
    "   - The system parses the generated action, executes the corresponding tool, and stores the tool’s result as a new **observation**.\n",
    "\n",
    "4. **Looping Process**\n",
    "   - The updated prompt (including the new observation) is passed back to the LLM.  \n",
    "   - This loop continues until the model produces an action of type **`final_answer`**, signaling that the reasoning process is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc6694",
   "metadata": {},
   "source": [
    "## 6 Example: Population Comparison Task\n",
    "\n",
    "**System prompt:**  \n",
    "> \"You are an agent that can browse the web and call tools. Use reasoning and then act.\"\n",
    "\n",
    "**User query:**  \n",
    "> \"Find the current population of Venice and compare it to that of Trento.\"\n",
    "\n",
    "\n",
    "### Step-by-Step Execution\n",
    "\n",
    "#### 1. Initialization\n",
    "   - The system stores the user’s query as a `TaskStep`.\n",
    "\n",
    "#### 2. First Iteration\n",
    "   - **Thought:** “To compare populations, I first need the population of Venice, then that of Trento, and finally compute their ratio.”  \n",
    "   - **Action:**  \n",
    "     ```json\n",
    "     {\"tool\": \"search_engine\", \"query\": \"population of Venice Italy 2025\"}\n",
    "     ```\n",
    "   - **Observation:** “Venice population: 254,000 (2024 estimate).”\n",
    "\n",
    "#### 3. Second Iteration\n",
    "   - **Thought:** “Now I need the population of Trento.”  \n",
    "   - **Action:**  \n",
    "     ```json\n",
    "     {\"tool\": \"search_engine\", \"query\": \"population of Trento Italy 2025\"}\n",
    "     ```\n",
    "   - **Observation:** “Trento population: 118,000 (2023 estimate).”\n",
    "\n",
    "#### 4. Third Iteration\n",
    "   - **Thought:** “I have both values; now compute the ratio.”  \n",
    "   - **Action:**  \n",
    "     ```json\n",
    "     {\"tool\": \"calculator\", \"expression\": \"118000 / 254000\"}\n",
    "     ```\n",
    "   - **Observation:** “Result: 0.46.”\n",
    "\n",
    "#### 5. Final Iteration\n",
    "   - **Thought:** “I now have the answer.”  \n",
    "   - **Action:**  \n",
    "     ```json\n",
    "     {\"tool\": \"final_answer\", \"output\": \"The population of Trento is approximately 46% of that of Venice.\"}\n",
    "     ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f52e2",
   "metadata": {},
   "source": [
    "## 7 Introduction to Smolagents\n",
    "\n",
    "`smolagents` is one of the simplest and most lightweight frameworks for building *ReAct-style AI Agents*.  \n",
    "It supports multiple Large Language Models (LLMs), including models from:\n",
    "\n",
    "- Hugging Face Hub  \n",
    "- OpenAI  \n",
    "- Anthropic  \n",
    "- And others\n",
    "\n",
    "The library implements the **ReAct framework** and allows you to:\n",
    "\n",
    "- Define custom tools\n",
    "- Use pre-built tools\n",
    "- Build multi-agent systems where agents collaborate on tasks\n",
    "\n",
    "`smolagents` provides two main agent types:\n",
    "\n",
    "- **ToolCallingAgent**: uses JSON/text-structured tool calls  \n",
    "- **CodeAgent** — writes Python code as its actions and executes it in a sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfd8bf",
   "metadata": {},
   "source": [
    "### 7.1 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc98fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (3.11.10) (Python 3.11.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/Users/christianmoiola/VS Code/Smolagents/venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%pip install \"smolagents[toolkit]\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690b643",
   "metadata": {},
   "source": [
    "### 7.2 ToolCallingAgent\n",
    "\n",
    "The `ToolCallingAgent` provides a direct implementation of the ReAct framework.\n",
    "It generates:\n",
    "\n",
    "1. A **reasoning step** (“Thought”)\n",
    "2. An **action step**, expressed as a JSON tool call\n",
    "\n",
    "It then selects and executes tools based on the reasoning produced by the LLM.\n",
    "\n",
    "Below is an example using a predefined search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, InferenceClientModel, DuckDuckGoSearchTool\n",
    "\n",
    "model = InferenceClientModel(\n",
    "    model_id=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[DuckDuckGoSearchTool()],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "agent.run(\"Who is the CEO of Hugging Face?\")\n",
    "agent.run(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21cefd",
   "metadata": {},
   "source": [
    "In this example, the agent only has access to a single tool for web search,\n",
    "so every action requiring external information will rely on that tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c0a92",
   "metadata": {},
   "source": [
    "### 7.3 Creating a Custom Tool\n",
    "\n",
    "We can create new tools using the `@tool` decorator.\n",
    "It is important that:\n",
    "\n",
    "* The **function name** is descriptive\n",
    "* The **parameters** clearly represent the intended inputs\n",
    "* The **docstring** explains exactly what the tool does\n",
    "\n",
    "The LLM relies heavily on this descriptive information to decide when the tool is relevant.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b41f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, InferenceClientModel, tool, DuckDuckGoSearchTool\n",
    "\n",
    "@tool\n",
    "def turn_on_lights(room: str) -> str:\n",
    "    \"\"\"\n",
    "    Turns on the lights in the specified room.\n",
    "\n",
    "    Args:\n",
    "        room: One of \"living room\", \"kitchen\", \"bedroom\", or \"bathroom\".\n",
    "    \"\"\"\n",
    "    if room not in [\"living room\", \"kitchen\", \"bedroom\", \"bathroom\"]:\n",
    "        raise ValueError(\"Invalid room name.\")\n",
    "    return f\"The lights in the {room} have been turned on.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6a872",
   "metadata": {},
   "source": [
    "Using it with a ToolCallingAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceClientModel(\n",
    "    model_id=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[turn_on_lights, DuckDuckGoSearchTool()],\n",
    "    model=model\n",
    ")\n",
    "\n",
    "agent.run(\"Based on the weather in New York, should I turn on the lights in the living room?\")\n",
    "agent.run(\"What is 458x123?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef80b1",
   "metadata": {},
   "source": [
    "#### Limitation of ToolCallingAgent\n",
    "\n",
    "If the agent needs functionality that has not been implemented as a tool,\n",
    "then:\n",
    "\n",
    "* it **cannot fall back to native reasoning**, and\n",
    "* it **cannot tell the user that it lacks a tool**\n",
    "\n",
    "Instead, it will produce an answer based only on its internal language model capabilities.\n",
    "\n",
    "For example, without a calculator tool, `458×123` will be computed directly by the LLM.\n",
    "\n",
    "To support more flexible and expressive actions, we can use the **CodeAgent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ed8d8",
   "metadata": {},
   "source": [
    "### 7.4 CodeAgent\n",
    "\n",
    "Unlike the `ToolCallingAgent`, which produces JSON tool calls,\n",
    "the **CodeAgent writes Python code** as its action.\n",
    "This code may:\n",
    "\n",
    "* Call custom tools\n",
    "* Perform arbitrary computations\n",
    "* Use Python’s built-in capabilities\n",
    "\n",
    "All code is executed in a **sandboxed environment**, and anything printed (`print(...)`) is treated as an **observation** and fed back into the ReAct loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c785b",
   "metadata": {},
   "source": [
    "#### Example: ToolCallingAgent vs CodeAgent Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf92b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ToolCallingAgent action\n",
    "tool_calling_agent_actions = {\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"turn_on_lights\",\n",
    "    \"arguments\": {\n",
    "      \"room\": \"kitchen\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Example CodeAgent action\n",
    "result = turn_on_lights(\"kitchen\")\n",
    "print(result)\n",
    "final_answer(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f9916",
   "metadata": {},
   "source": [
    "Because the CodeAgent can write code, it can compute operations (like multiplication)\n",
    "even without a calculator tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08b4b1",
   "metadata": {},
   "source": [
    "#### CodeAgent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool\n",
    "\n",
    "model = InferenceClientModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[turn_on_lights, DuckDuckGoSearchTool()],\n",
    "    model=model,\n",
    "    additional_authorized_imports=[]\n",
    ")\n",
    "\n",
    "agent.run(\"Turn on the lights in the kitchen.\")\n",
    "agent.run(\"What is 34x76?\")\n",
    "agent.run(\"What is the current date and time?\")\n",
    "agent.run(\"Search for the latest news about space exploration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c988050",
   "metadata": {},
   "source": [
    "With this setup, the agent becomes extremely powerful,\n",
    "but also potentially too large in scope if many tools are added.\n",
    "\n",
    "This motivates the use of **multi-agent systems**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07f18b",
   "metadata": {},
   "source": [
    "### 7.5 Multi-Agent Systems in Smolagents\n",
    "\n",
    "A multi-agent system consists of **multiple AI agents**,\n",
    "each with:\n",
    "\n",
    "* A dedicated role\n",
    "* A specific set of tools\n",
    "* A specialized responsibility\n",
    "\n",
    "This design increases:\n",
    "\n",
    "* **Modularity**\n",
    "* **Scalability**\n",
    "* **Robustness**\n",
    "\n",
    "Instead of giving one massive agent too many capabilities,\n",
    "tasks are distributed across specialized sub-agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdc8a2f",
   "metadata": {},
   "source": [
    "### 7.6 Multi-Agent Architecture\n",
    "\n",
    "A common pattern is:\n",
    "\n",
    "* An **orchestrator agent** \n",
    "* Several **specialized sub-agents**, such as:\n",
    "\n",
    "  * Web search agent\n",
    "  * Code execution agent\n",
    "  * Memory agent\n",
    "  * User-interaction agent\n",
    "\n",
    "The orchestrator delegates tasks to the appropriate agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00eabac",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, InferenceClientModel, WebSearchTool, UserInputTool\n",
    "\n",
    "model = InferenceClientModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "   tools=[WebSearchTool()],\n",
    "   model=model,\n",
    "   name=\"web_search_agent\",\n",
    "   description=\"Runs web searches for you. Provide a query.\"\n",
    ")\n",
    "\n",
    "user_agent = CodeAgent(\n",
    "   tools=[UserInputTool()],\n",
    "   model=model,\n",
    "   name=\"user_agent\",\n",
    "   description=\"Interacts with the user to understand their requests.\"\n",
    ")\n",
    "\n",
    "memory_agent = CodeAgent(\n",
    "   tools=[],\n",
    "   model=model,\n",
    "   name=\"memory_agent\",\n",
    "   description=\"Stores and retrieves information as needed.\"\n",
    ")\n",
    "\n",
    "code_agent = CodeAgent(\n",
    "   tools=[],\n",
    "   model=model,\n",
    "   name=\"code_agent\",\n",
    "   description=\"Executes Python code to perform computational tasks.\"\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "   tools=[],\n",
    "   model=model,\n",
    "   managed_agents=[web_agent, user_agent, memory_agent, code_agent]\n",
    ")\n",
    "\n",
    "manager_agent.run(\"Who is the CEO of Hugging Face?\")\n",
    "manager_agent.run(\"What is the capital of France?\")\n",
    "manager_agent.run(\"Remember that my favorite color is blue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce581d4d",
   "metadata": {},
   "source": [
    "### 7.7 Problems\n",
    "\n",
    "1. **AI-Agents do not truly plan:** They only output a “thought” message before generating an action or code, but this does not necessarily mean they are actually planning or reasoning.\n",
    "\n",
    "2. **AI agents attempt tasks they cannot perform:** They try to execute actions they are not capable of handling.\n",
    "\n",
    "3. **Lack of fallback policies:** When executing tool calls, if the model generates an incorrect json, errors occur because no fallback or recovery mechanisms exist.\n",
    "\n",
    "4. **Potential infinite loops:** As seen in some code executions or tool-calling sequences, ReAct-style loops of “thought, action, observation” can continue indefinitely.\n",
    "\n",
    "5. **Difficulty handling complex tasks:** How can these systems manage complex tasks? Can they genuinely reason?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
